{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotPoke(x):\n",
    "    f, a = plt.subplots(2, 8, figsize=(8, 2))\n",
    "    for i in range(8):\n",
    "        a[0][i].imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "        a[0,i].axis('off')\n",
    "        a[1][i].imshow(x[i+8], cmap=plt.get_cmap('gray'))\n",
    "        a[1,i].axis('off')\n",
    "    f.show()\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (792, 40, 40, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create an empty array to store pokemon pics\n",
    "orig_img = np.empty((0, 40, 40, 3), dtype='float32')\n",
    "# Load all images and append into orig_img\n",
    "path = os.path.abspath(\"./AE_RGB.ipynb\")\n",
    "path = re.sub('[a-zA-Z\\s._]+$', '', path)\n",
    "for pic in glob.glob(path+'Pokemon/*.png'):\n",
    "    img = mpimg.imread(pic)\n",
    "    # remove alpha channel  %some alpha=0 but RGB is not equal to [1., 1., 1.]\n",
    "    img[img[:,:,3]==0] = np.ones((1,4))\n",
    "    img = img[:,:,0:3]\n",
    "    orig_img = np.append(orig_img, [img], axis=0)\n",
    "\n",
    "# Use plt to show original images \n",
    "print 'Input data shape: {}'.format(orig_img.shape)\n",
    "# plotPoke(orig_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "batch_size = 24\n",
    "display_step = 100\n",
    "examples_to_show = 8\n",
    "\n",
    "# Network Parameters\n",
    "n_input = [40, 40, 3] # Pokemon data input (img shape: 40*40*3)\n",
    "n_channel1 = 16\n",
    "n_channel2 = 32\n",
    "n_channel3 = 64\n",
    "gen_dim = 100\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(tf.float32, [None]+n_input)\n",
    "Z = tf.placeholder(tf.float32, [None, gen_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weights & biases\n",
    "weights = {\n",
    "    'dis_h1': tf.Variable(tf.truncated_normal([5, 5, 3, n_channel2], stddev=0.01)),\n",
    "    'dis_h2': tf.Variable(tf.truncated_normal([5, 5, n_channel2, n_channel3], stddev=0.01)),\n",
    "    'dis_h3': tf.Variable(tf.truncated_normal([10*10*n_channel3, 1], stddev=0.01)),\n",
    "\n",
    "    'gen_h1': tf.Variable(tf.truncated_normal([gen_dim, 5*5*n_channel3], stddev=0.01)),\n",
    "    'gen_h2': tf.Variable(tf.truncated_normal([5, 5, n_channel2, n_channel3], stddev=0.01)),\n",
    "    'gen_h3': tf.Variable(tf.truncated_normal([5, 5, n_channel1, n_channel2], stddev=0.01)),\n",
    "    'gen_h4': tf.Variable(tf.truncated_normal([5, 5, 3, n_channel1], stddev=0.01))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'dis_h1': tf.Variable(tf.truncated_normal([n_channel2], stddev=0.01)),\n",
    "    'dis_h2': tf.Variable(tf.truncated_normal([n_channel3], stddev=0.01)),\n",
    "    'dis_h3': tf.Variable(tf.truncated_normal([1], stddev=0.01)),\n",
    "    \n",
    "    'gen_h1': tf.Variable(tf.truncated_normal([5*5*n_channel3], stddev=0.01)),\n",
    "    'gen_h2': tf.Variable(tf.truncated_normal([n_channel2], stddev=0.01)),\n",
    "    'gen_h3': tf.Variable(tf.truncated_normal([n_channel1], stddev=0.01)),\n",
    "    'gen_h4': tf.Variable(tf.truncated_normal([3], stddev=0.01))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=2):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def deconv2d(x, W, b, out_shape, strides=2):\n",
    "    x = tf.nn.conv2d_transpose(x, W, out_shape, strides=[1, strides, strides, 1], \n",
    "                               padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.sigmoid(x)\n",
    "\n",
    "def project(x, W, b):\n",
    "    return tf.nn.relu(tf.add(tf.matmul(x, W), b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z):\n",
    "    hidden_g1 = project(z, weights['gen_h1'], biases['gen_h1'])\n",
    "    hidden_g1 = tf.reshape(hidden_g1, [-1, 5, 5, n_channel3])\n",
    "    \n",
    "    output_dim2 = tf.stack([tf.shape(z)[0], 10, 10, n_channel2])\n",
    "    hidden_g2 = deconv2d(hidden_g1, weights['gen_h2'], biases['gen_h2'], output_dim2)\n",
    "    \n",
    "    output_dim3 = tf.stack([tf.shape(z)[0], 20, 20, n_channel1])\n",
    "    hidden_g3 = deconv2d(hidden_g2, weights['gen_h3'], biases['gen_h3'], output_dim3)\n",
    "    \n",
    "    output_dim4 = tf.stack([tf.shape(z)[0], 40, 40, 3])\n",
    "    hidden_g4 = deconv2d(hidden_g3, weights['gen_h4'], biases['gen_h4'], output_dim4)\n",
    "    \n",
    "    return hidden_g4\n",
    "\n",
    "def discriminator(x):\n",
    "    hidden_d1 = conv2d(x, weights['dis_h1'], biases['dis_h1'])\n",
    "    hidden_d2 = conv2d(hidden_d1, weights['dis_h2'], biases['dis_h2'])\n",
    "    hidden_d2 = tf.reshape(hidden_d2, [-1, 10*10*n_channel3])\n",
    "    \n",
    "    hidden_d3 = project(hidden_d2, weights[\"dis_h3\"], biases['dis_h3'])\n",
    "    return hidden_d3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct discriminator and generator\n",
    "gen_sample = generator(Z)\n",
    "dis_real= discriminator(X)\n",
    "dis_fake = discriminator(gen_sample)\n",
    "\n",
    "# Define loss\n",
    "dis_loss = -tf.reduce_mean(tf.log(dis_real) + tf.log(1.-dis_fake))\n",
    "gen_loss = -tf.reduce_mean(tf.log(dis_fake))\n",
    "\n",
    "# Optimizer for discriminator\n",
    "var_dis = [weights[i] for i in weights if re.match('dis', i)]+[biases[i] for i in biases if re.match('dis', i)]\n",
    "dis_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(dis_loss, var_list= var_dis)\n",
    "# Optimizer for generator parameters\n",
    "var_gen = [weights[i] for i in weights if re.match('gen', i)]+[biases[i] for i in biases if re.match('gen', i)]\n",
    "gen_optimizer = tf.train.AdamOptimizer(learning_rate).minimize(gen_loss, var_list= var_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function: sample data for generator\n",
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1., 1., size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create session and graph, initial variables\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load previous trained model and rewrite to variables, if exists\n",
    "# Before run this cell, you have to run the cell above first, to define variables and init it.\n",
    "weightSaver = tf.train.Saver(var_list=weights)\n",
    "biaseSaver = tf.train.Saver(var_list=biases)\n",
    "\n",
    "weightSaver.restore(sess, \"./saved_model/Conv_AE_weights.ckpt\")\n",
    "biaseSaver.restore(sess, \"./saved_model/Conv_AE_biases.ckpt\")\n",
    "\n",
    "print \"Model restored.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001   Discriminator loss: 1.386294   Generator loss: 1.386294\n",
      "Epoch: 00100   Discriminator loss: 1.386294   Generator loss: 1.386294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9e9b74d49b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Run optimization op (backprop) and loss op (to get loss value)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdis_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_Z\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Display logs per epoch step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = int(orig_img.shape[0]/batch_size)\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    # Loop over all batches\n",
    "    start = 0; end = batch_size\n",
    "    for i in range(total_batch):\n",
    "        index = np.arange(start, end)\n",
    "        np.random.shuffle(index)\n",
    "        batch_xs = orig_img[index]\n",
    "        start = end+1; end = start+batch_size\n",
    "        # Run optimization op (backprop) and loss op (to get loss value)\n",
    "        _, d_loss_train = sess.run([dis_optimizer, dis_loss], feed_dict = {X: batch_xs, Z: sample_Z(batch_size, gen_dim)})\n",
    "        _, g_loss_train = sess.run([gen_optimizer, gen_loss], feed_dict = {Z: sample_Z(batch_size, gen_dim)})\n",
    "    # Display logs per epoch step\n",
    "    if ((epoch == 0) or (epoch+1) % display_step == 0) or ((epoch+1) == training_epochs):\n",
    "        print 'Epoch: {0:04d}   Discriminator loss: {1:f}   Generator loss: {1:f}'.format(epoch+1, d_loss_train, g_loss_train)\n",
    "\n",
    "print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
